{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Creation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import newspaper\n",
    "import ast\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275686, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>...</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>replies</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>pid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SirT6</td>\n",
       "      <td>The title sort of misses the point of the stud...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;The title sort ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1447279564</td>\n",
       "      <td>1447250764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>t3_3se6lu</td>\n",
       "      <td>{u'kind': u'Listing', u'data': {u'modhash': No...</td>\n",
       "      <td>1359</td>\n",
       "      <td>science</td>\n",
       "      <td>1359</td>\n",
       "      <td>3se6lu</td>\n",
       "      <td>Counter({'alga': 5, 'cancer': 4, 'cell': 4, 'd...</td>\n",
       "      <td>869</td>\n",
       "      <td>52</td>\n",
       "      <td>{u'toxinalgae': 1.00993377483, u'cancer': 1.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DrBiochemistry</td>\n",
       "      <td>Just want to point out that until I see a deli...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;Just want to po...</td>\n",
       "      <td>0</td>\n",
       "      <td>1447277409</td>\n",
       "      <td>1447248609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>t3_3se6lu</td>\n",
       "      <td>{u'kind': u'Listing', u'data': {u'modhash': No...</td>\n",
       "      <td>3209</td>\n",
       "      <td>science</td>\n",
       "      <td>3209</td>\n",
       "      <td>3se6lu</td>\n",
       "      <td>Counter({'kill': 2, 'deliveri': 2, 'cancer': 1...</td>\n",
       "      <td>307</td>\n",
       "      <td>30</td>\n",
       "      <td>{u'survives': 1.02941176471, u'thing': 1.02941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frogblood</td>\n",
       "      <td>It's an interesting idea but the in vitro and ...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;It&amp;amp;#39;s an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1447276156</td>\n",
       "      <td>1447247356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>t3_3se6lu</td>\n",
       "      <td>{u'kind': u'Listing', u'data': {u'modhash': No...</td>\n",
       "      <td>133</td>\n",
       "      <td>science</td>\n",
       "      <td>133</td>\n",
       "      <td>3se6lu</td>\n",
       "      <td>Counter({'idea': 2, 'target': 2, 'overexcit': ...</td>\n",
       "      <td>432</td>\n",
       "      <td>39</td>\n",
       "      <td>{u'tumour': 1.02173913043, u'targeting': 1.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mijn_ikke</td>\n",
       "      <td>Just waiting until somebody smarter than me co...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;Just waiting un...</td>\n",
       "      <td>0</td>\n",
       "      <td>1447275611</td>\n",
       "      <td>1447246811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1447248944.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>t3_3se6lu</td>\n",
       "      <td>{u'kind': u'Listing', u'data': {u'modhash': No...</td>\n",
       "      <td>773</td>\n",
       "      <td>science</td>\n",
       "      <td>773</td>\n",
       "      <td>3se6lu</td>\n",
       "      <td>Counter({'thank': 1, 'gold': 1, 'point': 1, 'e...</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>{u'somebody': 1.05172413793, u'gold': 1.051724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awhitt8</td>\n",
       "      <td>Yes the title is sensationalized.\\n\\n&amp;gt;The m...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;Yes the title i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1447284967</td>\n",
       "      <td>1447256167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1447259263.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>t3_3se6lu</td>\n",
       "      <td>{u'kind': u'Listing', u'data': {u'modhash': No...</td>\n",
       "      <td>16</td>\n",
       "      <td>science</td>\n",
       "      <td>16</td>\n",
       "      <td>3se6lu</td>\n",
       "      <td>Counter({'drug': 5, 'deliveri': 4, 'materi': 3...</td>\n",
       "      <td>1447</td>\n",
       "      <td>104</td>\n",
       "      <td>{u'silicon': 1.01530612245, u'tissue': 1.01530...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                               body  \\\n",
       "0           SirT6  The title sort of misses the point of the stud...   \n",
       "1  DrBiochemistry  Just want to point out that until I see a deli...   \n",
       "2       Frogblood  It's an interesting idea but the in vitro and ...   \n",
       "3       mijn_ikke  Just waiting until somebody smarter than me co...   \n",
       "4         awhitt8  Yes the title is sensationalized.\\n\\n&gt;The m...   \n",
       "\n",
       "                                           body_html  controversiality  \\\n",
       "0  &lt;div class=\"md\"&gt;&lt;p&gt;The title sort ...                 0   \n",
       "1  &lt;div class=\"md\"&gt;&lt;p&gt;Just want to po...                 0   \n",
       "2  &lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s an...                 0   \n",
       "3  &lt;div class=\"md\"&gt;&lt;p&gt;Just waiting un...                 0   \n",
       "4  &lt;div class=\"md\"&gt;&lt;p&gt;Yes the title i...                 0   \n",
       "\n",
       "      created  created_utc distinguished downs        edited gilded  \\\n",
       "0  1447279564   1447250764           NaN     0         False      1   \n",
       "1  1447277409   1447248609           NaN     0         False      0   \n",
       "2  1447276156   1447247356           NaN     0         False      0   \n",
       "3  1447275611   1447246811           NaN     0  1447248944.0      1   \n",
       "4  1447284967   1447256167           NaN     0  1447259263.0      0   \n",
       "\n",
       "                         ...                          parent_id  \\\n",
       "0                        ...                          t3_3se6lu   \n",
       "1                        ...                          t3_3se6lu   \n",
       "2                        ...                          t3_3se6lu   \n",
       "3                        ...                          t3_3se6lu   \n",
       "4                        ...                          t3_3se6lu   \n",
       "\n",
       "                                             replies score subreddit   ups  \\\n",
       "0  {u'kind': u'Listing', u'data': {u'modhash': No...  1359   science  1359   \n",
       "1  {u'kind': u'Listing', u'data': {u'modhash': No...  3209   science  3209   \n",
       "2  {u'kind': u'Listing', u'data': {u'modhash': No...   133   science   133   \n",
       "3  {u'kind': u'Listing', u'data': {u'modhash': No...   773   science   773   \n",
       "4  {u'kind': u'Listing', u'data': {u'modhash': No...    16   science    16   \n",
       "\n",
       "      pid                                             tokens comment_length  \\\n",
       "0  3se6lu  Counter({'alga': 5, 'cancer': 4, 'cell': 4, 'd...            869   \n",
       "1  3se6lu  Counter({'kill': 2, 'deliveri': 2, 'cancer': 1...            307   \n",
       "2  3se6lu  Counter({'idea': 2, 'target': 2, 'overexcit': ...            432   \n",
       "3  3se6lu  Counter({'thank': 1, 'gold': 1, 'point': 1, 'e...            163   \n",
       "4  3se6lu  Counter({'drug': 5, 'deliveri': 4, 'materi': 3...           1447   \n",
       "\n",
       "  n_tokens                                           keywords  \n",
       "0       52  {u'toxinalgae': 1.00993377483, u'cancer': 1.03...  \n",
       "1       30  {u'survives': 1.02941176471, u'thing': 1.02941...  \n",
       "2       39  {u'tumour': 1.02173913043, u'targeting': 1.043...  \n",
       "3       12  {u'somebody': 1.05172413793, u'gold': 1.051724...  \n",
       "4      104  {u'silicon': 1.01530612245, u'tissue': 1.01530...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('./train_comments.csv',low_memory=False)\n",
    "comments[['body']] = comments[['body']].astype(str)\n",
    "comments['keywords'] = comments.keywords.apply(ast.literal_eval)\n",
    "comments.drop_duplicates(inplace=True,subset='id')\n",
    "comments.reset_index(drop=True)\n",
    "print comments.shape\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11420, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>downs</th>\n",
       "      <th>...</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>tokens</th>\n",
       "      <th>article_len</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Derek Keats Flickr, Hannah Osborne, Marc Cirera]</td>\n",
       "      <td>{u'cancer': 1.0261627907, u'drugs': 1.03052325...</td>\n",
       "      <td>2015-11-10 16:00:00+00:00</td>\n",
       "      <td>Algae has been genetically engineered to kill ...</td>\n",
       "      <td>Algae has been genetically engineered to kill ...</td>\n",
       "      <td>http://www.ibtimes.co.uk/algae-genetically-eng...</td>\n",
       "      <td>the_phet</td>\n",
       "      <td>1447239366</td>\n",
       "      <td>ibtimes.co.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/science/comments/3se6lu/algae_has_been_gene...</td>\n",
       "      <td>6705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>science</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/y1CGKgl69hKw-s...</td>\n",
       "      <td>Algae has been genetically engineered to kill ...</td>\n",
       "      <td>6705</td>\n",
       "      <td>Counter({'alga': 11, 'drug': 9, 'cell': 8, 'ca...</td>\n",
       "      <td>2352</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>{u'diamond': 1.04316546763, u'laser': 1.008633...</td>\n",
       "      <td>None</td>\n",
       "      <td>If Q-carbon is harder than diamond, why would ...</td>\n",
       "      <td>This is a collection of 0.02, 0.03 and 0.04 ca...</td>\n",
       "      <td>http://phys.org/news/2015-11-phase-carbon-diam...</td>\n",
       "      <td>skoalbrother</td>\n",
       "      <td>1448903226</td>\n",
       "      <td>phys.org</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/science/comments/3uvg0o/researchers_find_ne...</td>\n",
       "      <td>6777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>science</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/hZrhEdBoJp22oE...</td>\n",
       "      <td>Researchers find new phase of carbon, make dia...</td>\n",
       "      <td>6777</td>\n",
       "      <td>Counter({'diamond': 21, 'qcarbon': 15, 'carbon...</td>\n",
       "      <td>4626</td>\n",
       "      <td>4626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Bjorn Carey]</td>\n",
       "      <td>{u'obfuscation': 1.01181102362, u'fraud': 1.01...</td>\n",
       "      <td>2015-11-16 00:00:00</td>\n",
       "      <td>Stanford researchers uncover patterns in how s...</td>\n",
       "      <td>Stanford researchers uncover patterns in how s...</td>\n",
       "      <td>http://news.stanford.edu/news/2015/november/fr...</td>\n",
       "      <td>godsenfrik</td>\n",
       "      <td>1447707142</td>\n",
       "      <td>news.stanford.edu</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/science/comments/3t2exx/when_scientists_fal...</td>\n",
       "      <td>6259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>science</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/FQPskQP8EejVh9...</td>\n",
       "      <td>When scientists falsify data, they try to cove...</td>\n",
       "      <td>6259</td>\n",
       "      <td>Counter({'paper': 13, 'research': 11, 'scienti...</td>\n",
       "      <td>4253</td>\n",
       "      <td>4253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>{u'oil': 1.05142857143, u'microbes': 1.0114285...</td>\n",
       "      <td>None</td>\n",
       "      <td>And that leads to more questions about where m...</td>\n",
       "      <td>Samantha Joye, a professor of marine sciences ...</td>\n",
       "      <td>http://phys.org/news/2015-11-dispersants-oil-d...</td>\n",
       "      <td>avogadros_number</td>\n",
       "      <td>1447107697</td>\n",
       "      <td>phys.org</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/science/comments/3s6xe6/dispersants_did_not...</td>\n",
       "      <td>6146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>science</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/mFQzb4d2QNiyaE...</td>\n",
       "      <td>Dispersants did not help oil degrade in BP spi...</td>\n",
       "      <td>6146</td>\n",
       "      <td>Counter({'oil': 18, 'dispers': 12, 'joy': 11, ...</td>\n",
       "      <td>3330</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[More From]</td>\n",
       "      <td>{u'star': 1.02124645892, u'forming': 1.0106232...</td>\n",
       "      <td>2015-11-18 06:00:00</td>\n",
       "      <td>Together, the two observations allowed the sci...</td>\n",
       "      <td>Shares Share\\n\\nTweet\\n\\nE-mail\\n\\n​Of the tho...</td>\n",
       "      <td>http://www.popularmechanics.com/space/deep-spa...</td>\n",
       "      <td>Letmeirkyou</td>\n",
       "      <td>1447869624</td>\n",
       "      <td>popularmechanics.com</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/science/comments/3tbkv6/scientists_have_dis...</td>\n",
       "      <td>6020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>science</td>\n",
       "      <td>http://b.thumbs.redditmedia.com/spD7SnbKlAEY1y...</td>\n",
       "      <td>Scientists have discovered an exoplanet still ...</td>\n",
       "      <td>6020</td>\n",
       "      <td>Counter({'planet': 22, 'star': 12, 'sallum': 1...</td>\n",
       "      <td>4574</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0  [Derek Keats Flickr, Hannah Osborne, Marc Cirera]   \n",
       "1                                                 []   \n",
       "2                                      [Bjorn Carey]   \n",
       "3                                                 []   \n",
       "4                                        [More From]   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  {u'cancer': 1.0261627907, u'drugs': 1.03052325...   \n",
       "1  {u'diamond': 1.04316546763, u'laser': 1.008633...   \n",
       "2  {u'obfuscation': 1.01181102362, u'fraud': 1.01...   \n",
       "3  {u'oil': 1.05142857143, u'microbes': 1.0114285...   \n",
       "4  {u'star': 1.02124645892, u'forming': 1.0106232...   \n",
       "\n",
       "                publish_date  \\\n",
       "0  2015-11-10 16:00:00+00:00   \n",
       "1                       None   \n",
       "2        2015-11-16 00:00:00   \n",
       "3                       None   \n",
       "4        2015-11-18 06:00:00   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Algae has been genetically engineered to kill ...   \n",
       "1  If Q-carbon is harder than diamond, why would ...   \n",
       "2  Stanford researchers uncover patterns in how s...   \n",
       "3  And that leads to more questions about where m...   \n",
       "4  Together, the two observations allowed the sci...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Algae has been genetically engineered to kill ...   \n",
       "1  This is a collection of 0.02, 0.03 and 0.04 ca...   \n",
       "2  Stanford researchers uncover patterns in how s...   \n",
       "3  Samantha Joye, a professor of marine sciences ...   \n",
       "4  Shares Share\\n\\nTweet\\n\\nE-mail\\n\\n​Of the tho...   \n",
       "\n",
       "                                                 url            author  \\\n",
       "0  http://www.ibtimes.co.uk/algae-genetically-eng...          the_phet   \n",
       "1  http://phys.org/news/2015-11-phase-carbon-diam...      skoalbrother   \n",
       "2  http://news.stanford.edu/news/2015/november/fr...        godsenfrik   \n",
       "3  http://phys.org/news/2015-11-dispersants-oil-d...  avogadros_number   \n",
       "4  http://www.popularmechanics.com/space/deep-spa...       Letmeirkyou   \n",
       "\n",
       "   created_utc                domain  downs    ...     \\\n",
       "0   1447239366         ibtimes.co.uk      0    ...      \n",
       "1   1448903226              phys.org      0    ...      \n",
       "2   1447707142     news.stanford.edu      0    ...      \n",
       "3   1447107697              phys.org      0    ...      \n",
       "4   1447869624  popularmechanics.com      0    ...      \n",
       "\n",
       "                                           permalink score  selftext  \\\n",
       "0  /r/science/comments/3se6lu/algae_has_been_gene...  6705       NaN   \n",
       "1  /r/science/comments/3uvg0o/researchers_find_ne...  6777       NaN   \n",
       "2  /r/science/comments/3t2exx/when_scientists_fal...  6259       NaN   \n",
       "3  /r/science/comments/3s6xe6/dispersants_did_not...  6146       NaN   \n",
       "4  /r/science/comments/3tbkv6/scientists_have_dis...  6020       NaN   \n",
       "\n",
       "  subreddit                                          thumbnail  \\\n",
       "0   science  http://b.thumbs.redditmedia.com/y1CGKgl69hKw-s...   \n",
       "1   science  http://b.thumbs.redditmedia.com/hZrhEdBoJp22oE...   \n",
       "2   science  http://b.thumbs.redditmedia.com/FQPskQP8EejVh9...   \n",
       "3   science  http://b.thumbs.redditmedia.com/mFQzb4d2QNiyaE...   \n",
       "4   science  http://b.thumbs.redditmedia.com/spD7SnbKlAEY1y...   \n",
       "\n",
       "                                               title   ups  \\\n",
       "0  Algae has been genetically engineered to kill ...  6705   \n",
       "1  Researchers find new phase of carbon, make dia...  6777   \n",
       "2  When scientists falsify data, they try to cove...  6259   \n",
       "3  Dispersants did not help oil degrade in BP spi...  6146   \n",
       "4  Scientists have discovered an exoplanet still ...  6020   \n",
       "\n",
       "                                              tokens article_len  n_tokens  \n",
       "0  Counter({'alga': 11, 'drug': 9, 'cell': 8, 'ca...        2352      2352  \n",
       "1  Counter({'diamond': 21, 'qcarbon': 15, 'carbon...        4626      4626  \n",
       "2  Counter({'paper': 13, 'research': 11, 'scienti...        4253      4253  \n",
       "3  Counter({'oil': 18, 'dispers': 12, 'joy': 11, ...        3330      3330  \n",
       "4  Counter({'planet': 22, 'star': 12, 'sallum': 1...        4574      4574  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv('./train_articles.csv',low_memory=False)\n",
    "articles[['text','summary']] = articles[['text','summary']].astype(str)\n",
    "articles.drop_duplicates(inplace=True,subset = 'url')\n",
    "articles['keywords'] = articles.keywords.apply(ast.literal_eval)\n",
    "articles.reset_index(drop=True,inplace=True)\n",
    "print articles.shape\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'author', u'body', u'body_html', u'controversiality', u'created',\n",
      "       u'created_utc', u'distinguished', u'downs', u'edited', u'gilded', u'id',\n",
      "       u'likes', u'link_id', u'name', u'num_reports', u'parent_id', u'replies',\n",
      "       u'score', u'subreddit', u'ups', u'pid', u'tokens', u'comment_length',\n",
      "       u'n_tokens', u'keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Create Comment Features\n",
    "########################\n",
    "#Tokenized Comments\n",
    "\n",
    "import re, string\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "stopset = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_tokens(text):\n",
    "    lowers = text.lower()\n",
    "    clean = regex.sub('',lowers)\n",
    "    tokens=nltk.word_tokenize(clean)\n",
    "    return [w for w in tokens if not w in stopset]\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "#Count Stemmed Tokens\n",
    "comments['tokens'] = comments.body.apply(lambda text: Counter(stem_tokens(get_tokens(text), stemmer)))\n",
    "\n",
    "#Comment Length\n",
    "comments['comment_length'] = comments.body.apply(len)\n",
    "\n",
    "#Number of Words\n",
    "comments['n_tokens'] = comments.tokens.apply(len)\n",
    "\n",
    "#Comment Keywords\n",
    "comments['keywords'] = comments.body.apply(newspaper.nlp.keywords)\n",
    "\n",
    "print comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'authors', u'keywords', u'publish_date', u'summary', u'text', u'url',\n",
       "       u'author', u'created_utc', u'domain', u'downs', u'gilded', u'is_self',\n",
       "       u'likes', u'media', u'id', u'num_comments', u'num_reports', u'over_18',\n",
       "       u'permalink', u'score', u'selftext', u'subreddit', u'thumbnail',\n",
       "       u'title', u'ups', u'tokens', u'article_len', u'n_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Article Features\n",
    "#########################\n",
    "#Tokens\n",
    "articles['tokens'] = articles['text'].apply(lambda text: Counter(stem_tokens(get_tokens(text), stemmer)))\n",
    "\n",
    "#Article Length\n",
    "articles['article_len'] = articles['text'].apply(len)\n",
    "\n",
    "#Number of Words\n",
    "articles['n_tokens'] = articles['text'].apply(len)\n",
    "\n",
    "articles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write the final article and comment data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles.to_csv('./train_articles.csv',sep=',',index=False)\n",
    "comments.to_csv('./train_comments.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have raw content, stemmed tokens, keywords for each comment and article. Now we can start to look at the relationships between comment content and article content. We compouted the length to normalize some of the similarities. \n",
    "\n",
    "Should use weighted sim like weightign each word by its tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keyword_sim(comment_row):\n",
    "    try:\n",
    "        c_kw = comment_row['keywords']\n",
    "        a_kw = articles[articles['id']==comment_row['pid']]['keywords'].iloc[0]\n",
    "        sim = get_cosine(c_kw,a_kw)\n",
    "    except:\n",
    "        sim = 0.0\n",
    "    return sim\n",
    "\n",
    "comments['keyword_sim']=comments.apply(keyword_sim,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def token_sim(comment_row):\n",
    "    try:\n",
    "        c = comment_row['tokens']\n",
    "        a = articles[articles['id']==comment_row['pid']]['tokens'].iloc[0]\n",
    "        sim = get_cosine(c,a)\n",
    "    except:\n",
    "        sim = 0.0\n",
    "    return sim\n",
    "\n",
    "comments['token_sim']=comments.apply(token_sim,axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here We Build a Vocab for each user\n",
    "user_vocab = {}\n",
    "for author,vocab in comments[['author','tokens']].groupby('author'):\n",
    "    user_vocab[author] = sum((Counter(dict(x)) for x in vocab.tokens),Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_vocab_tokens_sim(comment_row):\n",
    "    try:\n",
    "        c = user_vocab[comment_row.author]\n",
    "        a = articles[articles['id']==comment_row['pid']]['tokens'].iloc[0]\n",
    "        sim = get_cosine(c,a)\n",
    "    except:\n",
    "        sim = 0.0\n",
    "    return sim\n",
    "\n",
    "comments['user_vocab_tokens']=comments.apply(user_vocab_tokens_sim,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_vocab_kw_sim(comment_row):\n",
    "    try:\n",
    "        c = user_vocab[comment_row.author]\n",
    "        a = articles[articles['id']==comment_row['pid']]['keywords'].iloc[0]\n",
    "        sim = get_cosine(c,a)\n",
    "    except:\n",
    "        sim = 0.0\n",
    "    return sim\n",
    "\n",
    "comments['user_vocab_kw']=comments.apply(user_vocab_kw_sim,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'likes', u'link_id', u'name', u'parent_id', u'score',\n",
       "       u'subreddit', u'ups', u'pid', u'comment_length', u'n_tokens',\n",
       "       u'keyword_sim', u'token_sim', u'user_vocab_tokens', u'user_vocab_kw'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_features = comments[['id','likes','link_id','name','parent_id','score','subreddit','ups','pid','comment_length','n_tokens','keyword_sim','token_sim','user_vocab_tokens','user_vocab_kw']]\n",
    "sim_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim_features.to_csv('./new_sim_features.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim_features = pd.read_csv('./new_sim_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90    0.182951\n",
       "91    0.162302\n",
       "92    0.000000\n",
       "93    0.000000\n",
       "94    0.103394\n",
       "95    0.166022\n",
       "96    0.243600\n",
       "97    0.000000\n",
       "98    0.063660\n",
       "99    0.013082\n",
       "Name: user_vocab_kw, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_features.user_vocab_kw[90:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
